
project_name: "HPO"
group_name: "Tyqiangz"
run_name: "Distilbert"
task_name: "tyqiangz"
output_dir: './adapter_training_output'

hyperparameters:
  model_name_or_path: "distilbert-base-uncased"
  max_seq_length: 256
  do_lower_case: True
  train_batch_size_gpu: 4
  eval_batch_size_gpu: 4
  learning_rate: 3.0e-5
  optimizer_name: 'AdamW'
  scheduler_name: 'linear'
  num_train_epochs: 3
  seed: 42

